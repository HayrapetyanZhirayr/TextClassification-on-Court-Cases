{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc94ca6",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.5em;\">This noteboook is designed to refute or confirm the hypothesis that the name of a document category is related more to documents of that category than to documents of some other category.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee2561",
   "metadata": {},
   "source": [
    "$W = \\{w_1, w_2, \\ldots, w_m\\}$, $W$ is the vocabulary set.\n",
    "\n",
    "$D = \\{d_1, d_2, \\ldots, d_n\\}$, $d_i \\in 2^W$, $D$ is the set of documents, $2^W$ is the set of all subsets of $W$.\n",
    "\n",
    "$Y = \\{y_1, y_2, \\ldots, y_n\\}$, $y_i \\in \\{1, 2, \\ldots, k\\}$, $Y$ is the set of labels of documents.\n",
    "\n",
    "$\\nu : \\{1, 2, \\ldots, k\\} \\mapsto 2^W$, $\\nu(j)$ is the name of the $j$'th category, $j \\in \\{1, 2, \\ldots, k\\}$\n",
    "\n",
    "$\\mu : 2^W \\times 2^W \\mapsto \\mathbb{R}$, $\\mu$ is some measure of relation of two strings.\n",
    "\n",
    "Hypothesis: $\\mu(\\nu(y_i), d_i) > \\mu(\\nu(y_i), d_j)$  $\\forall y_i \\neq y_i$ or in other words the name of documents category should relate more to the text of that document than to the text of another document from any other category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0f8a1",
   "metadata": {},
   "source": [
    "The experiment is caried out on the small collecition of data parsed from kad.arbitr.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f70efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.join(\n",
    "        os.environ['CONDA_PREFIX'], \n",
    "        \"bin/AST-text-analysis\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "import ast_local\n",
    "# go get east FROM https://github.com/mikhaildubov/AST-text-analysis\n",
    "# WARNING :: DO NOT INSTALL EAST USING PIP\n",
    "import east\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import load_data\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173608a8",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cf5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_df = pd.read_csv('data/taxonomies/taxonomy_df.csv')\n",
    "cat_indices_str = ['28', '29', '30', '31', '32']\n",
    "cat_IDs = []\n",
    "cat_names = []\n",
    "for cat_idx in cat_indices_str:\n",
    "    catID = int(taxonomy_df[taxonomy_df['cCode']==cat_idx]['ID'])\n",
    "    cat_name = (taxonomy_df[taxonomy_df['cCode']==cat_idx]['Descr'].values[0])\n",
    "    cat_IDs.append(catID)\n",
    "    cat_names.append(cat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading labels to choose appropriate indices for cat_indices_str list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 113/113 [00:06<00:00, 17.97it/s]\n"
     ]
    }
   ],
   "source": [
    "READ_DIR ='data/cases_small_preprocessedLEMM/'\n",
    "\n",
    "Y = []\n",
    "for _, y in load_data.yield_preprocessed_json_from_disk(READ_DIR):\n",
    "    Y.append(y)\n",
    "Y = np.array(Y)\n",
    "n_docs = len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping casenumbers to categories IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_info = pd.read_csv('data/cases_info.csv')\n",
    "cases_d = dict(zip(cases_info['Number'], cases_info['CategoryID']))\n",
    "del cases_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_id = np.array(list(map(lambda case: cases_d[case], Y)))\n",
    "indices = np.array([i for i in range(len(Y_id)) if Y_id[i] in cat_IDs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each category from cat_indices_str list, we will choose fixed number of documents equal to the min number of documents of some category and build new list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs_per_cat = min(data_utils.build_count_dict(Y_id[indices]).values())\n",
    "indices_new = []\n",
    "for catID in cat_IDs:\n",
    "    indices_new += list(\n",
    "        np.random.choice(indices[Y_id[indices] == catID], size=n_docs_per_cat,\n",
    "                        replace=False)\n",
    "    )\n",
    "indices_new = np.array(sorted(indices_new))\n",
    "assert len(indices_new) == n_docs_per_cat*len(cat_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading texts from disk and preparing it for AST's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 113/113 [00:07<00:00, 14.86it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []; Y_id_s = []\n",
    "j = 0\n",
    "for x, y in load_data.yield_preprocessed_json_from_disk(READ_DIR):\n",
    "    if j in indices_new:\n",
    "        texts.append(x)\n",
    "        Y_id_s.append(cases_d[y])\n",
    "    j += 1\n",
    "Y_id_s = np.array(Y_id_s)\n",
    "topics = [' '.join(data_utils.preprocess_text(cat)) for cat in cat_names] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building ASTs for texts and fitting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4eecc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING AST'S FOR TEXTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 275/275 [00:17<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING relevance_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 275/275 [00:07<00:00, 37.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# measuring relevance of each category name to each text using Annotysed Suffix Trees\n",
    "ast_transformer = ast_local.AST()\n",
    "ast_transformer.fit(texts, topics)\n",
    "rel_mat = ast_transformer.relevance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each category from cat_indices_str averaging scores by texts from different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf28906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing a measure of each category to texts from it's category and to texts from another category to check the Hypothesis\n",
    "measure_mat = np.zeros(shape=(len(cat_indices_str), len(cat_indices_str)))\n",
    "for i, cat_idx in enumerate(cat_indices_str):\n",
    "    catID = cat_IDs[i]\n",
    "    text_mask = (Y_id_s == catID)\n",
    "    \n",
    "    cat_scores = np.mean(\n",
    "        rel_mat[text_mask],\n",
    "        axis=0\n",
    "    )\n",
    "    measure_mat[i] = cat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37262633, 0.31574915, 0.26968069, 0.33186648, 0.37404891],\n",
       "       [0.39602422, 0.50942503, 0.36475667, 0.42019368, 0.41566347],\n",
       "       [0.38110952, 0.35811023, 0.50288431, 0.4301786 , 0.40570195],\n",
       "       [0.37415341, 0.34817663, 0.38556567, 0.42427418, 0.39743716],\n",
       "       [0.36314742, 0.32716192, 0.34312918, 0.31857624, 0.58047568]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b39a45",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.5em;\">**Conclusion**: In each raw the value of the diag. element is biger than other values. This indicates that the category name is closer to its own texts than to the texts of another category. This may confirm the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting category of text by relevances to different category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 113/113 [00:07<00:00, 14.86it/s]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 2500\n",
    "indices = np.random.choice(np.arange(n_docs), size=SAMPLE_SIZE, replace=False)\n",
    "# idx_list = np.random.choice(np.arange(len(X)), size=N_SAMPLES)\n",
    "X_sub = []\n",
    "Y_id_sub =[]\n",
    "j = 0\n",
    "for x_str, y_case in load_data.yield_preprocessed_json_from_disk(READ_DIR):\n",
    "    if j in indices:\n",
    "        y_ID = cases_d[y_case]\n",
    "        if y_ID != -1:\n",
    "            X_sub.append(x_str)\n",
    "            Y_id_sub.append(y_ID)\n",
    "    j += 1\n",
    "Y_id_sub = np.array(Y_id_sub)\n",
    "    \n",
    "cat_IDs_sub = list(set(Y_id_sub))\n",
    "\n",
    "cat_indices_str_sub = []\n",
    "cat_names_sub = []\n",
    "for catID in cat_IDs_sub:\n",
    "    cat_name = (taxonomy_df[taxonomy_df['ID']==catID]['Descr'].values[0])\n",
    "    cat_idx =  (taxonomy_df[taxonomy_df['ID']==catID]['cCode'].values[0])\n",
    "    cat_indices_str_sub.append(cat_idx)\n",
    "    cat_names_sub.append(cat_name)\n",
    "\n",
    "topics_sub  = [' '.join(data_utils.preprocess_text(cat)) for cat in cat_names_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING AST'S FOR TEXTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:48<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING relevance_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2500/2500 [04:24<00:00,  9.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# measuring relevance of each category name to each text using Annotysed Suffix Trees\n",
    "ast_transformer_s = ast_local.AST()\n",
    "ast_transformer_s.fit(X_sub, topics_sub)\n",
    "rel_mat_sub = ast_transformer_s.relevance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ::  0.3372\n"
     ]
    }
   ],
   "source": [
    "predictions = rel_mat_sub.argmax(axis=1)\n",
    "acc = 0\n",
    "for i in range(len(predictions)):\n",
    "    predID = cat_IDs_sub[predictions[i]]\n",
    "    trueID = Y_id_sub[i]\n",
    "    acc += (trueID == predID)\n",
    "acc = acc / len(predictions)\n",
    "print('Accuracy :: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
